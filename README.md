<b>#STATUES CAN TALK</b>

This is a project made for Sapienza's course "Vision and Perception".

This is an accademic project that aim to spread the culture in a different and technological way.
Soon we hope to develop also an application that will be the final goal of this idea.
<br>
<br>
<br>


<b>##RUN THE CODE##</b>

To run this code (final.py) and doing the experiment you have to create a "Vision" folder on your google drive and put all this repo inside.

Otherwise you have to change the path of the loaded files in the code according to your repo disposition.

You can run the experiment for each video on "Try" folder changing the "video_path" variable on final.py (all video in "Try" repo are new video, and weren't use to train the classifier). You can also take a video and try it.
<br>
<br>
<br>


<b>##CODE TO BUILD DATASET AND CLASSIFIER##</b>

We have put also the code to build a new dataset '.pt' (from images) on "Dataset_creator" and to fine tune a classifier on "Classificator_training", 
but to use this code you have to adjust the path and maybe adjust some parameters based on your need.

We have also shared our data on datasets (images and tensors) and weights of classifier trained:
  - Dataset training (statue classification): https://drive.google.com/drive/folders/1KDm03tYHUkt9fzdbXXPIP47KZsIjDNha?usp=sharing
  - Dataset valid and test (statue classification): https://drive.google.com/drive/folders/1ip6mCyUyNNupA2C4yh0xXiGE5nj9Cf_B?usp=sharing
  - Dataset (human - statue classification): https://drive.google.com/drive/folders/1y93PGMy0u7GlheAGP-soClrGDqfgZscS?usp=sharing 
